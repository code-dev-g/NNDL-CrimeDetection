{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow_model_optimization as tfmot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('./data/crime_data_main.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data['Preprocessed'], data['class'], test_size=0.20, random_state=1, stratify=data['class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('./models/tokenizer.pickle', 'rb') as handle:\n",
    "    tokenizer = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxlen=50\n",
    "def get_sequences(tokenizer, X_train):\n",
    "    sequences = tokenizer.texts_to_sequences(X_train)\n",
    "    padded = tf.keras.preprocessing.sequence.pad_sequences(sequences, truncating = 'post', padding='post', maxlen=maxlen)\n",
    "    return padded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "padded_train_sequences = get_sequences(tokenizer, X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_4 (Embedding)     (None, 50, 16)            160000    \n",
      "                                                                 \n",
      " bidirectional_8 (Bidirectio  (None, 50, 40)           5920      \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " bidirectional_9 (Bidirectio  (None, 40)               9760      \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 64)                2624      \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 3)                 195       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 178,499\n",
      "Trainable params: 178,499\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.load_model('./models/tf_crime_model_m1.h5')\n",
    "model.compile( \n",
    "        optimizer=tf.keras.optimizers.Adam(0.0001), \n",
    "        loss =tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False), \n",
    "        metrics = [\"accuracy\"]\n",
    "    )\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "620/620 [==============================] - 16s 20ms/step - loss: 0.0846 - accuracy: 0.9709 - val_loss: 0.0768 - val_accuracy: 0.9743\n",
      "Epoch 2/5\n",
      "620/620 [==============================] - 11s 18ms/step - loss: 0.0770 - accuracy: 0.9741 - val_loss: 0.0708 - val_accuracy: 0.9759\n",
      "Epoch 3/5\n",
      "620/620 [==============================] - 12s 19ms/step - loss: 0.0710 - accuracy: 0.9752 - val_loss: 0.0647 - val_accuracy: 0.9775\n",
      "Epoch 4/5\n",
      "620/620 [==============================] - 11s 18ms/step - loss: 0.0659 - accuracy: 0.9772 - val_loss: 0.0605 - val_accuracy: 0.9789\n",
      "Epoch 5/5\n",
      "620/620 [==============================] - 11s 19ms/step - loss: 0.0610 - accuracy: 0.9792 - val_loss: 0.0557 - val_accuracy: 0.9805\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2cc472ca0>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    padded_train_sequences, y_train,\n",
    "    validation_data=(padded_train_sequences, y_train),\n",
    "    epochs=5,\n",
    "    callbacks=[tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=2)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "155/155 [==============================] - 1s 3ms/step - loss: 0.4843 - accuracy: 0.8864\n",
      "Restored model, accuracy: 88.64%\n"
     ]
    }
   ],
   "source": [
    "loss,acc = model.evaluate(get_sequences(tokenizer, X_test), y_test)\n",
    "print(\"Restored model, accuracy: {:5.2f}%\".format(100*acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dense layers train with pruning.\n",
    "def apply_pruning_to_dense(layer):\n",
    "  if isinstance(layer, tf.keras.layers.Dense):\n",
    "    return tfmot.sparsity.keras.prune_low_magnitude(layer)\n",
    "  return layer\n",
    "# Using `tf.keras.models.clone_model` to apply `apply_pruning_to_dense`  to the layers of the model.\n",
    "model_for_pruning = tf.keras.models.clone_model(model, clone_function = apply_pruning_to_dense)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_4 (Embedding)     (None, 50, 16)            160000    \n",
      "                                                                 \n",
      " bidirectional_8 (Bidirectio  (None, 50, 40)           5920      \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " bidirectional_9 (Bidirectio  (None, 40)               9760      \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " prune_low_magnitude_dense_4  (None, 64)               5186      \n",
      "  (PruneLowMagnitude)                                            \n",
      "                                                                 \n",
      " prune_low_magnitude_dense_5  (None, 3)                389       \n",
      "  (PruneLowMagnitude)                                            \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 181,255\n",
      "Trainable params: 178,499\n",
      "Non-trainable params: 2,756\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_for_pruning.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiling model for pruning.\n",
    "model_for_pruning.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(0.0001),\n",
    "    loss =tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False), metrics = [\"accuracy\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the Callbacks and assigning the log directory.\n",
    "logdir = 'content/logs'\n",
    "callbacks = [\n",
    "    tfmot.sparsity.keras.UpdatePruningStep(),\n",
    "    tfmot.sparsity.keras.PruningSummaries(log_dir=logdir),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "  4/620 [..............................] - ETA: 13s - loss: 0.0500 - accuracy: 0.9844  WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0189s vs `on_train_batch_end` time: 0.2104s). Check your callbacks.\n",
      "620/620 [==============================] - 17s 21ms/step - loss: 0.0588 - accuracy: 0.9802 - val_loss: 0.0549 - val_accuracy: 0.9813\n",
      "Epoch 2/5\n",
      "620/620 [==============================] - 12s 19ms/step - loss: 0.0549 - accuracy: 0.9812 - val_loss: 0.0508 - val_accuracy: 0.9831\n",
      "Epoch 3/5\n",
      "620/620 [==============================] - 12s 19ms/step - loss: 0.0517 - accuracy: 0.9824 - val_loss: 0.0472 - val_accuracy: 0.9844\n",
      "Epoch 4/5\n",
      "620/620 [==============================] - 12s 19ms/step - loss: 0.0483 - accuracy: 0.9839 - val_loss: 0.0437 - val_accuracy: 0.9853\n",
      "Epoch 5/5\n",
      "620/620 [==============================] - 12s 19ms/step - loss: 0.0456 - accuracy: 0.9846 - val_loss: 0.0419 - val_accuracy: 0.9857\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2cc76ee80>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fine tuning the model.\n",
    "model_for_pruning.fit(\n",
    "    padded_train_sequences, y_train,\n",
    "    validation_data=(padded_train_sequences, y_train),\n",
    "    epochs=5,\n",
    "    callbacks=[tfmot.sparsity.keras.UpdatePruningStep(), tfmot.sparsity.keras.PruningSummaries(log_dir=logdir),]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "155/155 [==============================] - 1s 3ms/step - loss: 0.5504 - accuracy: 0.8796\n",
      "Optimized model, accuracy: 87.96%\n"
     ]
    }
   ],
   "source": [
    "loss,acc = model_for_pruning.evaluate(get_sequences(tokenizer, X_test), y_test)\n",
    "print(\"Optimized model, accuracy: {:5.2f}%\".format(100*acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: Line magic function `%tensorboard` not found.\n"
     ]
    }
   ],
   "source": [
    "%tensorboard --logdir={logdir}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_for_pruning.save('models/pruned_keras_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_weights = tfmot.clustering.keras.cluster_weights\n",
    "CentroidInitialization =tfmot.clustering.keras.CentroidInitialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "clustering_params = { 'number_of_clusters': 16,  'cluster_centroids_init': CentroidInitialization.LINEAR}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "clustered_model = cluster_weights(model, **clustering_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "clustered_model.compile(optimizer=tf.keras.optimizers.Adam(0.0001), loss =tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False), metrics = [\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " cluster_embedding_4 (Cluste  (None, 50, 16)           320016    \n",
      " rWeights)                                                       \n",
      "                                                                 \n",
      " cluster_bidirectional_8 (Cl  (None, 50, 40)           11744     \n",
      " usterWeightsRNN)                                                \n",
      "                                                                 \n",
      " cluster_bidirectional_9 (Cl  (None, 40)               19424     \n",
      " usterWeightsRNN)                                                \n",
      "                                                                 \n",
      " cluster_dense_4 (ClusterWei  (None, 64)               5200      \n",
      " ghts)                                                           \n",
      "                                                                 \n",
      " cluster_dense_5 (ClusterWei  (None, 3)                403       \n",
      " ghts)                                                           \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 356,787\n",
      "Trainable params: 178,675\n",
      "Non-trainable params: 178,112\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "clustered_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "620/620 [==============================] - 22s 29ms/step - loss: 0.0495 - accuracy: 0.9824 - val_loss: 0.0429 - val_accuracy: 0.9852\n",
      "Epoch 2/5\n",
      "620/620 [==============================] - 17s 27ms/step - loss: 0.0456 - accuracy: 0.9848 - val_loss: 0.0405 - val_accuracy: 0.9870\n",
      "Epoch 3/5\n",
      "620/620 [==============================] - 17s 27ms/step - loss: 0.0440 - accuracy: 0.9852 - val_loss: 0.0406 - val_accuracy: 0.9861\n",
      "Epoch 4/5\n",
      "620/620 [==============================] - 17s 27ms/step - loss: 0.0426 - accuracy: 0.9860 - val_loss: 0.0471 - val_accuracy: 0.9834\n",
      "Epoch 5/5\n",
      "620/620 [==============================] - 17s 28ms/step - loss: 0.0410 - accuracy: 0.9863 - val_loss: 0.0361 - val_accuracy: 0.9880\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2dc387a60>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clustered_model.fit(\n",
    "    padded_train_sequences, y_train,\n",
    "    validation_data=(padded_train_sequences, y_train),\n",
    "    epochs=5,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "155/155 [==============================] - 1s 7ms/step - loss: 0.6213 - accuracy: 0.8790\n",
      "Clustered model, accuracy: 87.90%\n"
     ]
    }
   ],
   "source": [
    "loss,acc = clustered_model.evaluate(get_sequences(tokenizer, X_test), y_test)\n",
    "print(\"Clustered model, accuracy: {:5.2f}%\".format(100*acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    }
   ],
   "source": [
    "final_model = tfmot.clustering.keras.strip_clustering(clustered_model)\n",
    "clustered_keras_file = 'models/weight_clustered_keras_model.h5'\n",
    "tf.keras.models.save_model(final_model, clustered_keras_file, include_optimizer=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " cluster_embedding_4 (Cluste  (None, 50, 16)           320016    \n",
      " rWeights)                                                       \n",
      "                                                                 \n",
      " cluster_bidirectional_8 (Cl  (None, 50, 40)           11744     \n",
      " usterWeightsRNN)                                                \n",
      "                                                                 \n",
      " cluster_bidirectional_9 (Cl  (None, 40)               19424     \n",
      " usterWeightsRNN)                                                \n",
      "                                                                 \n",
      " cluster_dense_4 (ClusterWei  (None, 64)               5200      \n",
      " ghts)                                                           \n",
      "                                                                 \n",
      " cluster_dense_5 (ClusterWei  (None, 3)                403       \n",
      " ghts)                                                           \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 356,787\n",
      "Trainable params: 178,675\n",
      "Non-trainable params: 178,112\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "clustered_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
